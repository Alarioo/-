- [分发脚本](#分发脚本)
- [Hadoop](#hadoop)
  - [集群启动与关闭](#集群启动与关闭)
# 分发脚本 
```
#!/bin/bash 
 
#1. 判断参数个数 
# 判断参数是否小于1
if [ $# -lt 1 ]   
then 
    echo Not Enough Arguement! 
    exit; 
fi 

#2. 遍历集群所有机器 
# 对102，103，104都进行分发
for host in hadoop102 hadoop103 hadoop104 
do 
   echo ====================  $host  ==================== 
   #3. 遍历所有目录，挨个发送 
   for file in $@ 
   do 

        #4. 判断文件是否存在 
        if [ -e $file ] 
            then 
                #5. 获取父目录 
                pdir=$(cd -P $(dirname $file); pwd) 
                
                #6. 获取当前文件的名称 
                fname=$(basename $file) 
                ssh $host "mkdir -p $pdir" 
                rsync -av $pdir/$fname $host:$pdir 
            # 如果不存在
            else 
                echo $file does not exists! 
        fi 
    done 
done
```
# Hadoop
## 集群启动与关闭
```
#!/bin/bash 
 
if [ $# -lt 1 ] 
then 
    echo "No Args Input..." 
    exit ; 
fi 
 
case $1 in 
"start") 
        echo " =================== 启动 hadoop 集群 ===================" 
 
        echo " --------------- 启动 hdfs ---------------" 
        ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh" 
        echo " --------------- 启动 yarn ---------------" 
        ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh" 
        echo " --------------- 启动 historyserver ---------------" 
        ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver" 
;; 
"stop") 
        echo " =================== 关闭 hadoop 集群 ===================" 
 
        echo " --------------- 关闭 historyserver ---------------" 
        ssh hadoop102 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver" 
        echo " --------------- 关闭 yarn ---------------" 
        ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh" 
        echo " --------------- 关闭 hdfs ---------------" 
        ssh hadoop102 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh" 
;; 
*) 
    echo "Input Args Error..." 
;; 
esac 
```
